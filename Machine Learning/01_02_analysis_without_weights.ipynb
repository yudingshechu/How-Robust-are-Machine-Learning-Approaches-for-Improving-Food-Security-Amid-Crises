{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file generates the real/original-data results without class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "predictorList = ['FCSStaus_lag', 'urban','NL_District_log', 'FoodInsecureMonthly_lag', \n",
    "       'precipitationMean', 'NDVI.Anomaly.Mean',\n",
    "       'Average..mm.',  'X1.Month.Anomaly....', 'X3.Months.Anomaly....', \n",
    "       'fatalitiesMean_log','temperatureMean_log','NDVIMean_log',\n",
    "       'Kind.Income.Ratio','MaleRatio', 'AvgAge', 'SelfArg', 'SelfHerd', 'ShareToilet_Yes', 'Salt_Yes',\n",
    "       'HouseType_feq', 'RoofType_feq', 'WaterSource_feq', 'IncomeStab_Somewhat stable',\n",
    "       'IncomeStab_Very unstable',\n",
    "       'SubjectivePoverty_Neither poor nor rich', 'SubjectivePoverty_Poor',\n",
    "       'SubjectivePoverty_Very poor', 'RelLivStandard_Better off',\n",
    "       'RelLivStandard_Same', 'RelLivStandard_Worse off',\n",
    "       'LivStandChange_Decreased', 'LivStandChange_Increased',\n",
    "       'LivStandChange_Stayed at the same', 'DistDrinkingWaterBig3', 'FamilySize', \n",
    "       'SelfStapleTypes', 'valueNow_MobilePhone', 'valueNowTotal', 'valueNow_Furniture', \n",
    "        'valueNow_MobilePhone_new', 'valueNow_ArgLand_new', 'valueNow_ArgLand', 'valueNow_Livestock', \n",
    "       'valueNow_Furniture_new', 'valueNow_Livestock_new', 'valueNowTotal_new', 'Income_new', 'Income', \n",
    "       'ValueAgoTotal_new', 'valueNow_FixPhone',  \n",
    "       'valueNow_Refrigerator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we generate the original data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    r\"bld\\datasets\\generated\\data_before_county.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_before_district.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_before_subcounty.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_county.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_district.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_subcounty.pkl\"\n",
    "]\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        data_dict[path] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_before_county = data_dict['bld\\\\datasets\\\\generated\\\\data_before_county.pkl']\n",
    "data_before_district = data_dict['bld\\\\datasets\\\\generated\\\\data_before_district.pkl']\n",
    "data_before_subcounty = data_dict['bld\\\\datasets\\\\generated\\\\data_before_subcounty.pkl']\n",
    "data_during_county = data_dict['bld\\\\datasets\\\\generated\\\\data_during_county.pkl']\n",
    "data_during_district = data_dict['bld\\\\datasets\\\\generated\\\\data_during_district.pkl']\n",
    "data_during_subcounty = data_dict['bld\\\\datasets\\\\generated\\\\data_during_subcounty.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_before_county_train = data_before_county['StdTrain_county_during']['train_10']\n",
    "data_before_district_train = data_before_district['StdTrain_district_during']['train_10']\n",
    "data_before_subcounty_train = data_before_subcounty['StdTrain_subcounty_during']['train_10']\n",
    "data_during_county_train = data_during_county['StdTrain_county']['train_10']\n",
    "data_during_district_train = data_during_district['StdTrain_district']['train_10']\n",
    "data_during_subcounty_train = data_during_subcounty['StdTrain_subcounty']['train_10']\n",
    "data_before_county_test = data_before_county['StdTest_county_during']['test_10']\n",
    "data_before_district_test = data_before_district['StdTest_district_during']['test_10']\n",
    "data_before_subcounty_test = data_before_subcounty['StdTest_subcounty_during']['test_10']\n",
    "data_during_county_test = data_during_county['StdTest_county']['test_10']\n",
    "data_during_district_test = data_during_district['StdTest_district']['test_10']\n",
    "data_during_subcounty_test = data_during_subcounty['StdTest_subcounty']['test_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_LR_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    LR_l1 = LogisticRegression(penalty='l1', random_state=527, solver='liblinear', max_iter=1000)\n",
    "    # grid = dict(C=loguniform(0.001, 1000))\n",
    "    grid = dict(C=loguniform(0.001, 1000))\n",
    "    crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring, random_state=527)\n",
    "    # crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    LR_l2 = LogisticRegression(penalty='l1', random_state=527, max_iter=1000, **crossval.best_params_, solver='liblinear')\n",
    "    LR_l2.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    y_LRpredprob_test = LR_l2.predict_proba(X_test)[:, 1]\n",
    "    AUC_LR = roc_auc_score(Y_test, y_LRpredprob_test)\n",
    "    output_df = {'Prob': y_LRpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_LR, LR_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_LR_district_before, AUC_LR_district_before, LR_l2_district_before = train_LR_and_bootstrap( data_before_district_train, data_before_district_test, predictorList)\n",
    "output_df_LR_district_during, AUC_LR_district_during, LR_l2_district_during = train_LR_and_bootstrap( data_during_district_train, data_during_district_test, predictorList)\n",
    "output_df_LR_subcounty_before, AUC_LR_subcounty_before, LR_l2_subcounty_before = train_LR_and_bootstrap( data_before_subcounty_train, data_before_subcounty_test, predictorList)\n",
    "output_df_LR_subcounty_during, AUC_LR_subcounty_during, LR_l2_subcounty_during = train_LR_and_bootstrap( data_during_subcounty_train, data_during_subcounty_test, predictorList)\n",
    "output_df_LR_county_before, AUC_LR_county_before, LR_l2_county_before = train_LR_and_bootstrap( data_before_county_train, data_before_county_test, predictorList)\n",
    "output_df_LR_county_during, AUC_LR_county_during, LR_l2_county_during = train_LR_and_bootstrap( data_during_county_train, data_during_county_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_LR_district_before).to_csv('bld/single_case_before/output_df_LR_district_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_during).to_csv('bld/single_case/output_df_LR_district_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_subcounty_before).to_csv('bld/single_case_before/output_df_LR_subcounty_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_subcounty_during).to_csv('bld/single_case/output_df_LR_subcounty_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_county_before).to_csv('bld/single_case_before/output_df_LR_county_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_county_during).to_csv('bld/single_case/output_df_LR_county_noW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_dict_models_noW = {\n",
    "    'LR_l2_district_before': LR_l2_district_before,\n",
    "    'LR_l2_district_during': LR_l2_district_during,\n",
    "    'LR_l2_subcounty_before': LR_l2_subcounty_before,\n",
    "    'LR_l2_subcounty_during': LR_l2_subcounty_during,\n",
    "    'LR_l2_county_before': LR_l2_county_before,\n",
    "    'LR_l2_county_during': LR_l2_county_during\n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/single_case_noW/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}LR_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(LR_dict_models_noW, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_RF_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    param_grid = dict(max_depth = range(3, 11), \n",
    "                    max_features = range(3, 8),\n",
    "                    min_samples_leaf = range(50, 201, 50))\n",
    "    \n",
    "    RF = RandomForestClassifier(random_state=527)\n",
    "    crossval = RandomizedSearchCV(RF, param_grid, cv=5, scoring=scoring, n_iter=100)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    RF_best = RandomForestClassifier(n_estimators=800, random_state=527, **crossval.best_params_)\n",
    "    RF_best.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    \n",
    "    y_RFpred_test = RF_best.predict(X_test)\n",
    "    y_RFpredprob_test = RF_best.predict_proba(X_test)[:, 1]\n",
    "    AUC_RF = roc_auc_score(Y_test, y_RFpredprob_test)\n",
    "    output_df = {'Prob': y_RFpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_RF, RF_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_XGB_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    param_test6 = dict(max_depth = range(3, 8), min_child_weight = uniform(loc=1, scale=9),\n",
    "                          gamma = uniform(loc=0.5, scale=1.5), subsample = uniform(loc=0.6, scale=0.4),\n",
    "                            colsample_bytree = uniform(loc=0.4, scale=0.4), reg_lambda = uniform(loc=100, scale=1400))\n",
    "    \n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    gsearch6 = RandomizedSearchCV(estimator=XGBClassifier(learning_rate=0.05, n_estimators=800,\n",
    "                                                    objective='binary:logistic', nthread=4,seed=27),\n",
    "                            param_distributions = param_test6, scoring=scoring, n_jobs=-1, cv=5, n_iter=100)\n",
    "    \n",
    "    gsearch6.fit(X_train, Y_train)\n",
    "    \n",
    "    paraFinalTrain = {**gsearch6.best_params_}\n",
    "    xgb4 = XGBClassifier(learning_rate=0.01, n_estimators=4000,\n",
    "                         **paraFinalTrain,\n",
    "                         objective='binary:logistic', nthread=4,seed=527)\n",
    "    xgb4.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "\n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "\n",
    "    y_XGBpredprob_test = xgb4.predict_proba(X_test)[:, 1]\n",
    "    AUC_XGB = roc_auc_score(Y_test, y_XGBpredprob_test)\n",
    "    output_df = {'Prob': y_XGBpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_XGB, xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_RF_district_before, AUC_RF_district_before, RF_district_before = train_RF_and_bootstrap( data_before_district_train, data_before_district_test, predictorList)\n",
    "output_df_RF_district_during, AUC_RF_district_during, RF_district_during = train_RF_and_bootstrap( data_during_district_train, data_during_district_test, predictorList)\n",
    "output_df_RF_subcounty_before, AUC_RF_subcounty_before, RF_subcounty_before = train_RF_and_bootstrap( data_before_subcounty_train, data_before_subcounty_test, predictorList)\n",
    "output_df_RF_subcounty_during, AUC_RF_subcounty_during, RF_subcounty_during = train_RF_and_bootstrap( data_during_subcounty_train, data_during_subcounty_test, predictorList)\n",
    "output_df_RF_county_before, AUC_RF_county_before, RF_county_before = train_RF_and_bootstrap( data_before_county_train, data_before_county_test, predictorList)\n",
    "output_df_RF_county_during, AUC_RF_county_during, RF_county_during = train_RF_and_bootstrap( data_during_county_train, data_during_county_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8127472527472527)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_RF_county_during"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_RF_district_before).to_csv('bld/single_case_before/output_df_RF_district_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_during).to_csv('bld/single_case/output_df_RF_district_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_subcounty_before).to_csv('bld/single_case_before/output_df_RF_subcounty_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_subcounty_during).to_csv('bld/single_case/output_df_RF_subcounty_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_county_before).to_csv('bld/single_case_before/output_df_RF_county_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_county_during).to_csv('bld/single_case/output_df_RF_county_noW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_dict_models_noW = {\n",
    "    'RF_best_district': RF_district_before,\n",
    "    'RF_best_district_during': RF_district_during,\n",
    "    'RF_best_subcounty': RF_subcounty_before,\n",
    "    'RF_best_subcounty_during': RF_subcounty_during,\n",
    "    'RF_best_county': RF_county_before,\n",
    "    'RF_best_county_during': RF_county_during\n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/single_case_noW/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}RF_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_dict_models_noW, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_XGB_district_before, AUC_XGB_district_before, XGB_district_before = train_XGB_and_bootstrap( data_before_district_train, data_before_district_test, predictorList)\n",
    "output_df_XGB_district_during, AUC_XGB_district_during, XGB_district_during = train_XGB_and_bootstrap( data_during_district_train, data_during_district_test, predictorList)\n",
    "output_df_XGB_subcounty_before, AUC_XGB_subcounty_before, XGB_subcounty_before = train_XGB_and_bootstrap( data_before_subcounty_train, data_before_subcounty_test, predictorList)\n",
    "output_df_XGB_subcounty_during, AUC_XGB_subcounty_during, XGB_subcounty_during = train_XGB_and_bootstrap( data_during_subcounty_train, data_during_subcounty_test, predictorList)\n",
    "output_df_XGB_county_before, AUC_XGB_county_before, XGB_county_before = train_XGB_and_bootstrap( data_before_county_train, data_before_county_test, predictorList)\n",
    "output_df_XGB_county_during, AUC_XGB_county_during, XGB_county_during = train_XGB_and_bootstrap( data_during_county_train, data_during_county_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_XGB_district_before).to_csv('bld/single_case_before/output_df_XGB_district_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_during).to_csv('bld/single_case/output_df_XGB_district_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_subcounty_before).to_csv('bld/single_case_before/output_df_XGB_subcounty_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_subcounty_during).to_csv('bld/single_case/output_df_XGB_subcounty_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_county_before).to_csv('bld/single_case_before/output_df_XGB_county_before_noW.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_county_during).to_csv('bld/single_case/output_df_XGB_county_noW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_dict_models = {\n",
    "    'xgb_district': XGB_district_before, \n",
    "    'xgb_district_during': XGB_district_during,\n",
    "    'xgb_subcounty': XGB_subcounty_before,\n",
    "    'xgb_subcounty_during': XGB_subcounty_during,\n",
    "    'xgb_county': XGB_county_before,\n",
    "    'xgb_county_during': XGB_county_during    \n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/single_case_noW/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}XGB_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(XGB_dict_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_dict = {'AUC_LR_district_before' : AUC_LR_district_before, 'AUC_LR_county_before' : AUC_LR_county_before, 'AUC_LR_subcounty_before' : AUC_LR_subcounty_before,\n",
    "                'AUC_LR_district_during' : AUC_LR_district_during, 'AUC_LR_county_during' : AUC_LR_county_during, 'AUC_LR_subcounty_during' : AUC_LR_subcounty_during}\n",
    "AUC_RF_dict = {'AUC_RF_district_before' : AUC_RF_district_before, 'AUC_RF_county_before' : AUC_RF_county_before, 'AUC_RF_subcounty_before' : AUC_RF_subcounty_before,\n",
    "                'AUC_RF_district_during' : AUC_RF_district_during, 'AUC_RF_county_during' : AUC_RF_county_during, 'AUC_RF_subcounty_during' : AUC_RF_subcounty_during}\n",
    "AUC_XGB_dict = {'AUC_XGB_district_before' : AUC_XGB_district_before, 'AUC_XGB_county_before' : AUC_XGB_county_before, 'AUC_XGB_subcounty_before' : AUC_XGB_subcounty_before,\n",
    "                'AUC_XGB_district_during' : AUC_XGB_district_during, 'AUC_XGB_county_during' : AUC_XGB_county_during, 'AUC_XGB_subcounty_during' : AUC_XGB_subcounty_during}\n",
    "pd.DataFrame(AUC_LR_dict, index=[0]).to_csv('bld/single_case_noW/AUC_LR_dict.csv', index=False)\n",
    "pd.DataFrame(AUC_RF_dict, index=[0]).to_csv('bld/single_case_noW/AUC_RF_dict.csv', index=False)\n",
    "pd.DataFrame(AUC_XGB_dict, index=[0]).to_csv('bld/single_case_noW/AUC_XGB_dict.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WD_food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
