{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "predictorList = ['FCSStaus_lag','NL_District_log', 'FoodInsecureMonthly_lag', \n",
    "       'precipitationMean', 'NDVI.Anomaly.Mean',\n",
    "       'Average..mm.',  'X1.Month.Anomaly....', 'X3.Months.Anomaly....', \n",
    "       'fatalitiesMean_log','temperatureMean_log','NDVIMean_log',\n",
    "       'MaleRatio', 'ShareToilet_Yes',\n",
    "        'WaterSource_feq', 'IncomeStab_Somewhat stable',\n",
    "       'IncomeStab_Very unstable',\n",
    "       'SubjectivePoverty_Neither poor nor rich', 'SubjectivePoverty_Poor',\n",
    "       'SubjectivePoverty_Very poor', 'RelLivStandard_Better off',\n",
    "       'RelLivStandard_Same', 'RelLivStandard_Worse off', 'FamilySize', \n",
    "       'SelfStapleTypes', 'valueNow_Furniture', \n",
    "       'valueNow_Furniture_new', 'ValueAgoTotal_new']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we generate the original data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    r\"bld\\datasets\\generated\\data_before_county.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_before_district.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_before_subcounty.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_county.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_district.pkl\",\n",
    "    r\"bld\\datasets\\generated\\data_during_subcounty.pkl\"\n",
    "]\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, 'rb') as file:\n",
    "        data_dict[path] = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_before_county = data_dict['bld\\\\datasets\\\\generated\\\\data_before_county.pkl']\n",
    "data_before_district = data_dict['bld\\\\datasets\\\\generated\\\\data_before_district.pkl']\n",
    "data_before_subcounty = data_dict['bld\\\\datasets\\\\generated\\\\data_before_subcounty.pkl']\n",
    "data_during_county = data_dict['bld\\\\datasets\\\\generated\\\\data_during_county.pkl']\n",
    "data_during_district = data_dict['bld\\\\datasets\\\\generated\\\\data_during_district.pkl']\n",
    "data_during_subcounty = data_dict['bld\\\\datasets\\\\generated\\\\data_during_subcounty.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_during_district_std = data_during_district['StdTrain_district']['train_10']\n",
    "data_during_district_ada = data_during_district['ADASYN_Train_district']['train_10']\n",
    "data_during_district_smote = data_during_district['SMOTE_Train_district']['train_10']\n",
    "data_during_district_smoteenn = data_during_district['SMOTEENN_Train_district']['train_10']\n",
    "data_during_district_smotetomek = data_during_district['SMOTETOM_Train_district']['train_10']\n",
    "data_during_district_test = data_during_district['StdTest_district']['test_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_LR_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    LR_l1 = LogisticRegression(penalty='l1', random_state=527, solver='liblinear', max_iter=1000,  class_weight='balanced')\n",
    "    # grid = dict(C=loguniform(0.001, 1000))\n",
    "    grid = dict(C=loguniform(0.001, 1000))\n",
    "    crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring, random_state=527)\n",
    "    # crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    LR_l2 = LogisticRegression(penalty='l1', random_state=527, max_iter=1000, **crossval.best_params_, solver='liblinear',  class_weight='balanced')\n",
    "    LR_l2.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    y_LRpredprob_test = LR_l2.predict_proba(X_test)[:, 1]\n",
    "    AUC_LR = roc_auc_score(Y_test, y_LRpredprob_test)\n",
    "    output_df = {'Prob': y_LRpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_LR, LR_l2\n",
    "\n",
    "def train_LR_and_bootstrap_noWe(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    LR_l1 = LogisticRegression(penalty='l1', random_state=527, solver='liblinear', max_iter=1000)\n",
    "    # grid = dict(C=loguniform(0.001, 1000))\n",
    "    grid = dict(C=loguniform(0.001, 1000))\n",
    "    crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring, random_state=527)\n",
    "    # crossval = RandomizedSearchCV(LR_l1, grid, cv=5, scoring=scoring)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    LR_l2 = LogisticRegression(penalty='l1', random_state=527, max_iter=1000, **crossval.best_params_, solver='liblinear')\n",
    "    LR_l2.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    y_LRpredprob_test = LR_l2.predict_proba(X_test)[:, 1]\n",
    "    AUC_LR = roc_auc_score(Y_test, y_LRpredprob_test)\n",
    "    output_df = {'Prob': y_LRpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_LR, LR_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_LR_district, AUC_LR_district, LR_l2_district = train_LR_and_bootstrap( data_during_district_std, data_during_district_test, predictorList)\n",
    "output_df_LR_district_ada, AUC_LR_district_ada, LR_l2_district_ada = train_LR_and_bootstrap( data_during_district_ada, data_during_district_test, predictorList)\n",
    "output_df_LR_district_smote, AUC_LR_district_smote, LR_l2_district_smote = train_LR_and_bootstrap( data_during_district_smote, data_during_district_test, predictorList)\n",
    "output_df_LR_district_smoteenn, AUC_LR_district_smoteenn, LR_l2_district_smoteenn = train_LR_and_bootstrap( data_during_district_smoteenn, data_during_district_test, predictorList)\n",
    "output_df_LR_district_smotetomek, AUC_LR_district_smotetomek, LR_l2_district_smotetomek = train_LR_and_bootstrap( data_during_district_smotetomek, data_during_district_test, predictorList)\n",
    "output_df_LR_district_noW, AUC_LR_district_noW, LR_l2_district_noW = train_LR_and_bootstrap_noWe( data_during_district_std, data_during_district_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_LR_district).to_csv('bld/select_feature/output_df_LR_district.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_ada).to_csv('bld/select_feature/output_df_LR_district_ada.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_smote).to_csv('bld/select_feature/output_df_LR_district_smote.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_smoteenn).to_csv('bld/select_feature/output_df_LR_district_smoteenn.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_smotetomek).to_csv('bld/select_feature/output_df_LR_district_smotetomek.csv', index=False)\n",
    "pd.DataFrame(output_df_LR_district_noW).to_csv('bld/select_feature/output_df_LR_district_noW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_dict_models_noW = {\n",
    "    'LR_l2_district': LR_l2_district,\n",
    "    'LR_l2_district_ada': LR_l2_district_ada,\n",
    "    'LR_l2_district_smote': LR_l2_district_smote,\n",
    "    'LR_l2_district_smoteenn': LR_l2_district_smoteenn,\n",
    "    'LR_l2_district_smotetomek': LR_l2_district_smotetomek, \n",
    "    'LR_l2_district_noW': LR_l2_district_noW\n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/select_feature/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}LR_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(LR_dict_models_noW, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_RF_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    param_grid = dict(max_depth = range(3, 11), \n",
    "                    max_features = range(3, 8),\n",
    "                    min_samples_leaf = range(50, 201, 50))\n",
    "    \n",
    "    RF = RandomForestClassifier(random_state=527,  class_weight='balanced')\n",
    "    crossval = RandomizedSearchCV(RF, param_grid, cv=5, scoring=scoring, n_iter=100)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    RF_best = RandomForestClassifier(n_estimators=800, random_state=527, **crossval.best_params_,  class_weight='balanced')\n",
    "    RF_best.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    \n",
    "    y_RFpred_test = RF_best.predict(X_test)\n",
    "    y_RFpredprob_test = RF_best.predict_proba(X_test)[:, 1]\n",
    "    AUC_RF = roc_auc_score(Y_test, y_RFpredprob_test)\n",
    "    output_df = {'Prob': y_RFpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_RF, RF_best\n",
    "\n",
    "\n",
    "def train_RF_and_bootstrap_noWe(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    \n",
    "    param_grid = dict(max_depth = range(3, 11), \n",
    "                    max_features = range(3, 8),\n",
    "                    min_samples_leaf = range(50, 201, 50))\n",
    "    \n",
    "    RF = RandomForestClassifier(random_state=527)\n",
    "    crossval = RandomizedSearchCV(RF, param_grid, cv=5, scoring=scoring, n_iter=100)\n",
    "    crossval.fit(X_train, Y_train)\n",
    "    \n",
    "    RF_best = RandomForestClassifier(n_estimators=800, random_state=527, **crossval.best_params_)\n",
    "    RF_best.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "    \n",
    "    y_RFpred_test = RF_best.predict(X_test)\n",
    "    y_RFpredprob_test = RF_best.predict_proba(X_test)[:, 1]\n",
    "    AUC_RF = roc_auc_score(Y_test, y_RFpredprob_test)\n",
    "    output_df = {'Prob': y_RFpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_RF, RF_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, loguniform\n",
    "from skopt import BayesSearchCV, space \n",
    "\n",
    "def train_XGB_and_bootstrap(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    param_test6 = dict(max_depth = range(3, 8), min_child_weight = uniform(loc=1, scale=9),\n",
    "                          gamma = uniform(loc=0.5, scale=1.5), subsample = uniform(loc=0.6, scale=0.4),\n",
    "                            colsample_bytree = uniform(loc=0.4, scale=0.4), reg_lambda = uniform(loc=100, scale=1400))\n",
    "    \n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    class_weight = Y_train.value_counts()[0] / Y_train.value_counts()[1]\n",
    "    gsearch6 = RandomizedSearchCV(estimator=XGBClassifier(learning_rate=0.05, n_estimators=800,\n",
    "                                                    objective='binary:logistic', scale_pos_weight=class_weight, nthread=4,seed=27),\n",
    "                            param_distributions = param_test6, scoring=scoring, n_jobs=-1, cv=5, n_iter=100)\n",
    "    \n",
    "    gsearch6.fit(X_train, Y_train)\n",
    "    \n",
    "    paraFinalTrain = {**gsearch6.best_params_}\n",
    "    xgb4 = XGBClassifier(learning_rate=0.01, n_estimators=4000,\n",
    "                         **paraFinalTrain, scale_pos_weight=class_weight, \n",
    "                         objective='binary:logistic', nthread=4,seed=527)\n",
    "    xgb4.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "\n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "\n",
    "    y_XGBpredprob_test = xgb4.predict_proba(X_test)[:, 1]\n",
    "    AUC_XGB = roc_auc_score(Y_test, y_XGBpredprob_test)\n",
    "    output_df = {'Prob': y_XGBpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_XGB, xgb4\n",
    "  \n",
    "  \n",
    "def train_XGB_and_bootstrap_noWe(train_data, test_data, predictor_list, scoring='roc_auc'):\n",
    "    '''\n",
    "    train_data: dataframe of training data, this case should be ...Train_...['train_10']\n",
    "    test_data: dictionary of testing data\n",
    "    '''\n",
    "    param_test6 = dict(max_depth = range(3, 8), min_child_weight = uniform(loc=1, scale=9),\n",
    "                          gamma = uniform(loc=0.5, scale=1.5), subsample = uniform(loc=0.6, scale=0.4),\n",
    "                            colsample_bytree = uniform(loc=0.4, scale=0.4), reg_lambda = uniform(loc=100, scale=1400))\n",
    "    \n",
    "    X_train = train_data[predictor_list]\n",
    "    Y_train = train_data['FCSStaus']\n",
    "    gsearch6 = RandomizedSearchCV(estimator=XGBClassifier(learning_rate=0.05, n_estimators=800,\n",
    "                                                    objective='binary:logistic', nthread=4,seed=27),\n",
    "                            param_distributions = param_test6, scoring=scoring, n_jobs=-1, cv=5, n_iter=100)\n",
    "    \n",
    "    gsearch6.fit(X_train, Y_train)\n",
    "    \n",
    "    paraFinalTrain = {**gsearch6.best_params_}\n",
    "    xgb4 = XGBClassifier(learning_rate=0.01, n_estimators=4000,\n",
    "                         **paraFinalTrain, \n",
    "                         objective='binary:logistic', nthread=4,seed=527)\n",
    "    xgb4.fit(X_train, Y_train)\n",
    "    # we first train and test the model with the original data \n",
    "\n",
    "    X_test = test_data[predictor_list]\n",
    "    Y_test = test_data['FCSStaus']\n",
    "\n",
    "    y_XGBpredprob_test = xgb4.predict_proba(X_test)[:, 1]\n",
    "    AUC_XGB = roc_auc_score(Y_test, y_XGBpredprob_test)\n",
    "    output_df = {'Prob': y_XGBpredprob_test, 'Y': Y_test}\n",
    "    \n",
    "    return output_df, AUC_XGB, xgb4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_RF_district, AUC_RF_district, RF_district = train_RF_and_bootstrap( data_during_district_std, data_during_district_test, predictorList)\n",
    "output_df_RF_district_adasyn, AUC_RF_district_adasyn, RF_district_adasyn = train_RF_and_bootstrap( data_during_district_ada, data_during_district_test, predictorList)\n",
    "output_df_RF_district_smote, AUC_RF_district_smote, RF_district_smote = train_RF_and_bootstrap( data_during_district_smote, data_during_district_test, predictorList)\n",
    "output_df_RF_district_smoteenn, AUC_RF_district_smoteenn, RF_district_smoteenn = train_RF_and_bootstrap( data_during_district_smoteenn, data_during_district_test, predictorList)\n",
    "output_df_RF_district_smotetomek, AUC_RF_district_smotetomek, RF_district_smotetomek = train_RF_and_bootstrap( data_during_district_smotetomek, data_during_district_test, predictorList)\n",
    "output_df_RF_district_noW, AUC_RF_district_noW, RF_district_noW = train_RF_and_bootstrap_noWe( data_during_district_std, data_during_district_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_RF_district).to_csv('bld/select_feature/output_df_RF_district.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_adasyn).to_csv('bld/select_feature/output_df_RF_district_adasyn.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_smote).to_csv('bld/select_feature/output_df_RF_district_smote.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_smoteenn).to_csv('bld/select_feature/output_df_RF_district_smoteenn.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_smotetomek).to_csv('bld/select_feature/output_df_RF_district_smotetomek.csv', index=False)\n",
    "pd.DataFrame(output_df_RF_district_noW).to_csv('bld/select_feature/output_df_RF_district_noW.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_dict_models_noW = {\n",
    "    'RF_district': RF_district,\n",
    "    'RF_district_adasyn': RF_district_adasyn,\n",
    "    'RF_district_smote': RF_district_smote,\n",
    "    'RF_district_smoteenn': RF_district_smoteenn,\n",
    "    'RF_district_smotetomek': RF_district_smotetomek,\n",
    "    'RF_district_noW': RF_district_noW\n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/select_feature/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}RF_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(RF_dict_models_noW, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df_XGB_district, AUC_XGB_district, XGB_district = train_XGB_and_bootstrap( data_during_district_std, data_during_district_test, predictorList)\n",
    "output_df_XGB_district_adasyn, AUC_XGB_district_adasyn, XGB_district_adasyn = train_XGB_and_bootstrap( data_during_district_ada, data_during_district_test, predictorList)\n",
    "output_df_XGB_district_smote, AUC_XGB_district_smote, XGB_district_smote = train_XGB_and_bootstrap( data_during_district_smote, data_during_district_test, predictorList)\n",
    "output_df_XGB_district_smoteenn, AUC_XGB_district_smoteenn, XGB_district_smoteenn = train_XGB_and_bootstrap( data_during_district_smoteenn, data_during_district_test, predictorList)\n",
    "output_df_XGB_district_smotetomek, AUC_XGB_district_smotetomek, XGB_district_smotetomek = train_XGB_and_bootstrap( data_during_district_smotetomek, data_during_district_test, predictorList)\n",
    "output_df_XGB_district_noW, AUC_XGB_district_noW, XGB_district_noW = train_XGB_and_bootstrap_noWe( data_during_district_std, data_during_district_test, predictorList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(output_df_XGB_district).to_csv('bld/select_feature/output_df_XGB_district.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_adasyn).to_csv('bld/select_feature/output_df_XGB_district_adasyn.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_smote).to_csv('bld/select_feature/output_df_XGB_district_smote.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_smoteenn).to_csv('bld/select_feature/output_df_XGB_district_smoteenn.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_smotetomek).to_csv('bld/select_feature/output_df_XGB_district_smotetomek.csv', index=False)\n",
    "pd.DataFrame(output_df_XGB_district_noW).to_csv('bld/select_feature/output_df_XGB_district_noW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB_dict_models = {\n",
    "    'XGB_district': XGB_district,\n",
    "    'XGB_district_adasyn': XGB_district_adasyn,\n",
    "    'XGB_district_smote': XGB_district_smote,\n",
    "    'XGB_district_smoteenn': XGB_district_smoteenn,\n",
    "    'XGB_district_smotetomek': XGB_district_smotetomek,\n",
    "    'XGB_district_noW': XGB_district_noW  \n",
    "}\n",
    "\n",
    "# Define the output directory\n",
    "output_dir = 'bld/select_feature/'\n",
    "\n",
    "# Store each dictionary as a pickle file\n",
    "with open(f'{output_dir}XGB_dict_models.pkl', 'wb') as f:\n",
    "    pickle.dump(XGB_dict_models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_LR_dict = {\n",
    "    'AUC_LR_district': AUC_LR_district,\n",
    "    'AUC_LR_district_ada': AUC_LR_district_ada,\n",
    "    'AUC_LR_district_smote': AUC_LR_district_smote,\n",
    "    'AUC_LR_district_smoteenn': AUC_LR_district_smoteenn,\n",
    "    'AUC_LR_district_smotetomek': AUC_LR_district_smotetomek,\n",
    "    'AUC_LR_district_noW': AUC_LR_district_noW\n",
    "}\n",
    "\n",
    "AUC_RF_dict = {\n",
    "    'AUC_RF_district': AUC_RF_district,\n",
    "    'AUC_RF_district_adasyn': AUC_RF_district_adasyn,\n",
    "    'AUC_RF_district_smote': AUC_RF_district_smote,\n",
    "    'AUC_RF_district_smoteenn': AUC_RF_district_smoteenn,\n",
    "    'AUC_RF_district_smotetomek': AUC_RF_district_smotetomek,\n",
    "    'AUC_RF_district_noW': AUC_RF_district_noW\n",
    "}\n",
    "\n",
    "AUC_XGB_dict = {\n",
    "    'AUC_XGB_district': AUC_XGB_district,\n",
    "    'AUC_XGB_district_adasyn': AUC_XGB_district_adasyn,\n",
    "    'AUC_XGB_district_smote': AUC_XGB_district_smote,\n",
    "    'AUC_XGB_district_smoteenn': AUC_XGB_district_smoteenn,\n",
    "    'AUC_XGB_district_smotetomek': AUC_XGB_district_smotetomek,\n",
    "    'AUC_XGB_district_noW': AUC_XGB_district_noW\n",
    "}\n",
    "\n",
    "pd.DataFrame(AUC_LR_dict, index=[0]).to_csv('bld/select_feature/AUC_LR_dict.csv', index=False)\n",
    "pd.DataFrame(AUC_RF_dict, index=[0]).to_csv('bld/select_feature/AUC_RF_dict.csv', index=False)\n",
    "pd.DataFrame(AUC_XGB_dict, index=[0]).to_csv('bld/select_feature/AUC_XGB_dict.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WD_food",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
